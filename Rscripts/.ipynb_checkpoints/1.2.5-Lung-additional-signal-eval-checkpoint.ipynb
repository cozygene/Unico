{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“package ‘MASS’ was built under R version 4.1.3”\n",
      "Welcome to compositions, a package for compositional data analysis.\n",
      "Find an intro with \"? compositions\"\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: ‘compositions’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    anova, cor, cov, dist, var\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    %*%, norm, scale, scale.default\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(matrixStats)\n",
    "source(\"analysis.utils.r\")\n",
    "source(\"simulate.expression.utils.r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source.col = \"decon.L1\" \n",
    "# n= 500\n",
    "\n",
    "# source.col = \"decon.L2\" \n",
    "# n= 500\n",
    "\n",
    "# source.col = \"decon.L1\" \n",
    "# n= 250\n",
    "\n",
    "source.col = \"decon.L1\" \n",
    "n= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_stds = 2\n",
    "project.dir = \"/u/home/j/johnsonc/project-halperin/TCAx/TCAx2023/\"\n",
    "\n",
    "#relative path of the data dir to project.dir\n",
    "if(source.col == \"decon.L1\"){\n",
    "    data.dir   = paste0(\"Data/RNA/Simulation-Lung/sc-HLCA_all.W_decon.L1_HEF.10k_k_4_m_600_n_\", n, \"_dirichlet_F_noiseZ_T_varThr_1e-04_filThr_1e-04_expQtl_0_enrich_F_etpRat_0_enrichRat_0_maxSds_\", max_stds,\"_scale.maxSds_Inf_scale.factor.thr_1e-04/\")\n",
    "    res.dir    = paste0(\"Result/RNA/Simulation-Lung/sc-HLCA_all.W_decon.L1_HEF.10k_k_4_m_600_n_\", n, \"_dirichlet_F_noiseZ_T_varThr_1e-04_filThr_1e-04_expQtl_0_enrich_F_etpRat_0_enrichRat_0_maxSds_\", max_stds,\"_scale.maxSds_Inf_scale.factor.thr_1e-04/\")\n",
    "}else{\n",
    "    data.dir   = paste0(\"Data/RNA/Simulation-Lung/sc-HLCA_all.W_decon.L2_HEF.10k_k_6_m_600_n_\", n, \"_dirichlet_F_noiseZ_T_varThr_1e-04_filThr_1e-04_expQtl_0_enrich_F_etpRat_0_enrichRat_0_maxSds_\", max_stds,\"_scale.maxSds_Inf_scale.factor.thr_1e-04/\")\n",
    "    res.dir    = paste0(\"Result/RNA/Simulation-Lung/sc-HLCA_all.W_decon.L2_HEF.10k_k_6_m_600_n_\", n, \"_dirichlet_F_noiseZ_T_varThr_1e-04_filThr_1e-04_expQtl_0_enrich_F_etpRat_0_enrichRat_0_maxSds_\", max_stds,\"_scale.maxSds_Inf_scale.factor.thr_1e-04/\")\n",
    "}\n",
    "\n",
    "ts = 1:20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dir   = file.path(project.dir, data.dir)\n",
    "res.dir   = file.path(project.dir, res.dir)\n",
    "\n",
    "if (!file.exists(res.dir)){print(\"no result in the result directory\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"mp_0_vp_0.01_cp_0.01_maxStds_2\"\n"
     ]
    }
   ],
   "source": [
    "sim.data.list = readRDS(file.path(data.dir, \"sim.data.list.rds\"))\n",
    "\n",
    "# load TCA, baseline\n",
    "tca.mdl.list  = readRDS(file.path(res.dir, paste0(\"tca.mdl.list.rds\")))\n",
    "base.mdl.list = readRDS(file.path(res.dir, paste0(\"base.mdl.list.rds\")))\n",
    "cibersortx.mdl.list = readRDS(file.path(res.dir, paste0(\"cibersortx.mdl.list.rds\")))\n",
    "\n",
    "## load TCAx\n",
    "mean_penalty  = 0\n",
    "var_penalty   = 0.01\n",
    "covar_penalty = 0.01\n",
    "\n",
    "pen.config = paste(\"mp\", mean_penalty, \"vp\", var_penalty, \"cp\", covar_penalty, \"maxStds\", max_stds, sep =  \"_\")\n",
    "print(pen.config)\n",
    "\n",
    "tcax.mdl.list = readRDS(file.path(res.dir, paste0(\"tcax.mdl.\", pen.config, \".list.rds\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X: matrix of features by sample, bulk expression or methylation \n",
    "#W: matric of samples by sources, proportions\n",
    "#Z: array of sources by features by samples, ground truth Z\n",
    "#Z.hat: array of sources by features by samples, estiamted Z\n",
    "#eval.feature.source: matrix of logical features by sources, \n",
    "#if True, evaluate this feature-source, if False, skip it. all components will have pval1\n",
    "#num.stds: numeric, number of standard deviations away to be considered as outliers and removed from regression \n",
    "#constant_thr: numeric, miminal amount of variation in Z.hat to be considered worth fitting the regression \n",
    "#if fall below this number, Z.hat automoatically get pval 1. regression only fit on the rest of the components\n",
    "\n",
    "#per feature-source fit the following regression\n",
    "#log(1 + Z[feature-source]) ~ 1 + W[drop one celltype] + log(1 + bulk[feature]) + log(1 + Z.hat[feature-source])\n",
    "#add the - (min Z.hat) to all Z.hat if there are any negative values in that feature,source\n",
    "#remove 2sd outliers based on bulk\n",
    "\n",
    "#return an array of pvalues that is source.ids by features by compents participates in the regression \n",
    "\n",
    "calc_joint_bulk_p_vals_array = function(X, W, Z, Z.hat, eval.feature.source, num.stds = 2, constant_thr = 10**(-4)){\n",
    "    # if there are negative value, shift entire distribution \n",
    "    Z.hat = none_neg_Z(Z.hat)\n",
    "\n",
    "    m = nrow(X)\n",
    "    k = ncol(W)\n",
    "    feature.ids = rownames(X)\n",
    "    source.ids  = colnames(W)\n",
    "    \n",
    "    # init to all 1 pval\n",
    "    p.vals.array = array(1, c(k, m, (1 + 1 + 1 + (k-1)))) # intercept, bulk, Z[,jl], W related,\n",
    "    dimnames(p.vals.array)[[1]] = source.ids  \n",
    "    dimnames(p.vals.array)[[2]] = feature.ids\n",
    "    dimnames(p.vals.array)[[3]] = c(\"(Intercept)\", \"bulk\", \"Z.hat\", colnames(W)[-1])\n",
    "\n",
    "    for (source.id in source.ids){\n",
    "        for (feature.id in feature.ids){\n",
    "            if (!eval.feature.source[feature.id, source.id]){\n",
    "                p.vals.array[source.id, feature.id, ] = NA\n",
    "                next # skip this feature source due to no meaningful variable in the ground truth Z\n",
    "                # everything is set to 1\n",
    "            }else{\n",
    "                df = data.frame(Z     = log(1 + Z[source.id,feature.id,]),     \n",
    "                                bulk  = log(1 + X[feature.id, ]), \n",
    "                                Z.hat = log(1 + Z.hat[source.id,feature.id,]))\n",
    "                df = cbind(df, data.frame(W[,-1])) # drop one celltype\n",
    "                \n",
    "                #filter out 2SD\n",
    "                x =  df$bulk\n",
    "                mask = abs(x - mean(x)) <= num.stds * sd(x)\n",
    "                df = df[mask, ]\n",
    "\n",
    "                if(sd(df$Z.hat) <= constant_thr){\n",
    "                    #if no variance detected in celltype h, gene j, \n",
    "                    df = df[, colnames(df)!= \"Z.hat\"]\n",
    "                    fit = lm(formula = Z ~ 1 + ., data = df) \n",
    "                    coef = summary(fit)$coefficients\n",
    "                    #prevent lm replacing the special characters in the colnames so hard code this\n",
    "                    p.vals.array[source.id, feature.id, c(\"(Intercept)\", \"bulk\", colnames(W[,-1]))] = t(coef[, \"Pr(>|t|)\", drop = F])\n",
    "                }else{\n",
    "                    fit = lm(formula = Z ~ 1 + ., data = df) \n",
    "                    coef = summary(fit)$coefficients\n",
    "                    p.vals.array[source.id, feature.id, ] = t(coef[, \"Pr(>|t|)\", drop = F])\n",
    "                }\n",
    "             }\n",
    "        }#end of feature\n",
    "    }#end of source\n",
    "    return(p.vals.array)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# running regression on all iterations, all methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "11.04 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "52.42 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "21.88 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "60.96 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "8.33 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "60.67 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "17.29 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "59.71 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "16.38 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "42.79 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "9.33 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "54.25 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "16.12 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "57.58 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "11 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "36.96 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "11.58 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "58.13 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "18.12 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "52.79 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "20.58 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "65.38 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "20.29 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "40.54 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "14.04 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "52.96 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "14.37 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "52.96 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "6.71 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "52.54 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "25.21 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "61.96 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "14.96 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "42.46 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "13.67 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "59.25 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "10.67 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "42.29 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "20.08 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "58.96 percent of the feature-source are shifted to be non negative\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for (t in ts){\n",
    "    sim.data.list[[t]]$eval.feature.source = calc_variable_feature_source(sim.data.list[[t]]$Z.scale, \n",
    "                                                                          variable_thr = 0.1, max_sds = max_stds)\n",
    "\n",
    "    base.mdl.list[[t]]$joint.bulk.p = calc_joint_bulk_p_vals_array(X = sim.data.list[[t]]$X,\n",
    "                                                                   W = sim.data.list[[t]]$W,\n",
    "                                                                   Z = sim.data.list[[t]]$Z,\n",
    "                                                                   Z.hat = base.mdl.list[[t]]$Z.hat.orig,\n",
    "                                                                   eval.feature.source = sim.data.list[[t]]$eval.feature.source)\n",
    "\n",
    "    \n",
    "    cibersortx.mdl.list[[t]]$joint.bulk.p = calc_joint_bulk_p_vals_array(X = sim.data.list[[t]]$X,\n",
    "                                                                         W = sim.data.list[[t]]$W,\n",
    "                                                                         Z = sim.data.list[[t]]$Z,\n",
    "                                                                         Z.hat = cibersortx.mdl.list[[t]]$Z.hat.orig,\n",
    "                                                                         eval.feature.source = sim.data.list[[t]]$eval.feature.source)\n",
    "\n",
    "    tca.mdl.list[[t]]$joint.bulk.p = calc_joint_bulk_p_vals_array(X = sim.data.list[[t]]$X,\n",
    "                                                                  W = sim.data.list[[t]]$W,\n",
    "                                                                  Z = sim.data.list[[t]]$Z,\n",
    "                                                                  Z.hat = tca.mdl.list[[t]]$Z.hat.orig,\n",
    "                                                                  eval.feature.source = sim.data.list[[t]]$eval.feature.source)\n",
    "    \n",
    "    tcax.mdl.list[[t]]$joint.bulk.p = calc_joint_bulk_p_vals_array(X = sim.data.list[[t]]$X,\n",
    "                                                                   W = sim.data.list[[t]]$W,\n",
    "                                                                   Z = sim.data.list[[t]]$Z,\n",
    "                                                                   Z.hat = tcax.mdl.list[[t]]$Z.hat.orig,\n",
    "                                                                   eval.feature.source = sim.data.list[[t]]$eval.feature.source)\n",
    "     \n",
    "    \n",
    "    \n",
    "    #celltype by features\n",
    "    base.mdl.list[[t]]$joint.bulk.Z.hat.log10p.diff = t(-log10(base.mdl.list[[t]]$joint.bulk.p[,,\"Z.hat\"])) - t(-log10(base.mdl.list[[t]]$joint.bulk.p[,,\"bulk\"]))\n",
    "    base.mdl.list[[t]]$joint.bulk.Z.hat.log10p      = t(-log10(base.mdl.list[[t]]$joint.bulk.p[,,\"Z.hat\"])) \n",
    "    \n",
    "    cibersortx.mdl.list[[t]]$joint.bulk.Z.hat.log10p.diff = t(-log10(cibersortx.mdl.list[[t]]$joint.bulk.p[,,\"Z.hat\"])) - t(-log10(cibersortx.mdl.list[[t]]$joint.bulk.p[,,\"bulk\"]))\n",
    "    cibersortx.mdl.list[[t]]$joint.bulk.Z.hat.log10p      = t(-log10(cibersortx.mdl.list[[t]]$joint.bulk.p[,,\"Z.hat\"])) \n",
    "   \n",
    "    tca.mdl.list[[t]]$joint.bulk.Z.hat.log10p.diff = t(-log10(tca.mdl.list[[t]]$joint.bulk.p[,,\"Z.hat\"])) - t(-log10(tca.mdl.list[[t]]$joint.bulk.p[,,\"bulk\"]))\n",
    "    tca.mdl.list[[t]]$joint.bulk.Z.hat.log10p      = t(-log10(tca.mdl.list[[t]]$joint.bulk.p[,,\"Z.hat\"]))\n",
    "    \n",
    "    tcax.mdl.list[[t]]$joint.bulk.Z.hat.log10p.diff = t(-log10(tcax.mdl.list[[t]]$joint.bulk.p[,,\"Z.hat\"])) - t(-log10(tcax.mdl.list[[t]]$joint.bulk.p[,,\"bulk\"])) \n",
    "    tcax.mdl.list[[t]]$joint.bulk.Z.hat.log10p      = t(-log10(tcax.mdl.list[[t]]$joint.bulk.p[,,\"Z.hat\"]))\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>-6.07036313871171</li><li>-3.4704563184144</li><li>-1.45531204689294</li><li>-1.13337651224412</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item -6.07036313871171\n",
       "\\item -3.4704563184144\n",
       "\\item -1.45531204689294\n",
       "\\item -1.13337651224412\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. -6.07036313871171\n",
       "2. -3.4704563184144\n",
       "3. -1.45531204689294\n",
       "4. -1.13337651224412\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] -6.070363 -3.470456 -1.455312 -1.133377"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# just on the first round\n",
    "colMedians(base.mdl.list[[1]]$joint.bulk.Z.hat.log10p.diff, na.rm = T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>-1.4170258058198</li><li>-1.83128416236326</li><li>-2.04058409532453</li><li>-1.90837452383463</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item -1.4170258058198\n",
       "\\item -1.83128416236326\n",
       "\\item -2.04058409532453\n",
       "\\item -1.90837452383463\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. -1.4170258058198\n",
       "2. -1.83128416236326\n",
       "3. -2.04058409532453\n",
       "4. -1.90837452383463\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] -1.417026 -1.831284 -2.040584 -1.908375"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colMedians(cibersortx.mdl.list[[1]]$joint.bulk.Z.hat.log10p.diff, na.rm = T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>-0.653675913878705</li><li>-1.58858989602854</li><li>-1.31209318600564</li><li>-1.59510712976693</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item -0.653675913878705\n",
       "\\item -1.58858989602854\n",
       "\\item -1.31209318600564\n",
       "\\item -1.59510712976693\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. -0.653675913878705\n",
       "2. -1.58858989602854\n",
       "3. -1.31209318600564\n",
       "4. -1.59510712976693\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] -0.6536759 -1.5885899 -1.3120932 -1.5951071"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colMedians(tca.mdl.list[[1]]$joint.bulk.Z.hat.log10p.diff, na.rm = T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>-0.398016729560762</li><li>0.076250592205028</li><li>-0.296301903436532</li><li>-0.600530162101587</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item -0.398016729560762\n",
       "\\item 0.076250592205028\n",
       "\\item -0.296301903436532\n",
       "\\item -0.600530162101587\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. -0.398016729560762\n",
       "2. 0.076250592205028\n",
       "3. -0.296301903436532\n",
       "4. -0.600530162101587\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] -0.39801673  0.07625059 -0.29630190 -0.60053016"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colMedians(tcax.mdl.list[[1]]$joint.bulk.Z.hat.log10p.diff, na.rm = T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #Time permit\n",
    "# options(repr.plot.width = 5, repr.plot.height = 5, repr.plot.res = 200)\n",
    "\n",
    "# plot(-log10(tcax.mdl.list[[1]]$joint.bulk.p[1,,\"bulk\"]), \n",
    "#      -log10(tcax.mdl.list[[1]]$joint.bulk.p[1,,\"Z.hat\"]), \n",
    "#      xlim=range(0,40), ylim=range(0,40), col = alpha(\"red\", 0.1))\n",
    "\n",
    "# options(repr.plot.width = 5, repr.plot.height = 5, repr.plot.res = 200)\n",
    "# plot(-log10(tca.mdl.list[[1]]$joint.bulk.p[1,,\"bulk\"]), \n",
    "#      -log10(tca.mdl.list[[1]]$joint.bulk.p[1,,\"Z.hat\"]),\n",
    "#      xlim=range(0,40), ylim=range(0,40), col = alpha(\"red\", 0.1))\n",
    "\n",
    "# options(repr.plot.width = 5, repr.plot.height = 5, repr.plot.res = 200)\n",
    "\n",
    "# plot(-log10(tca.mdl.list[[1]]$joint.bulk.p[1,,\"Z.hat\"]), \n",
    "#      -log10(tcax.mdl.list[[1]]$joint.bulk.p[1,,\"Z.hat\"]), \n",
    "#      xlim=range(0,40), ylim=range(0,40), col = alpha(\"red\", 0.1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveRDS(base.mdl.list,       file.path(res.dir, paste0(\"base.mdl.list.rds\"))) \n",
    "saveRDS(cibersortx.mdl.list, file.path(res.dir, paste0(\"cibersortx.mdl.list.rds\")))\n",
    "saveRDS(tca.mdl.list,        file.path(res.dir, paste0(\"tca.mdl.list.rds\")))\n",
    "saveRDS(tcax.mdl.list,       file.path(res.dir, paste0(\"tcax.mdl.\", pen.config, \".list.rds\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bMIND rough prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bMIND.mdl.list = readRDS(file.path(res.dir, paste0(\"bMIND.mdl.rough.prior.list.rds\")))\n",
    "for (t in ts){\n",
    "    sim.data.list[[t]]$eval.feature.source = calc_variable_feature_source(sim.data.list[[t]]$Z.scale, \n",
    "                                                                          variable_thr = 0.1, max_sds = max_stds)\n",
    "    bMIND.mdl.list[[t]]$joint.bulk.p = calc_joint_bulk_p_vals_array(X = sim.data.list[[t]]$X,\n",
    "                                                                    W = sim.data.list[[t]]$W,\n",
    "                                                                    Z = sim.data.list[[t]]$Z,\n",
    "                                                                    \n",
    "                                                                    Z.hat = exp(none_neg_Z(bMIND.mdl.list[[t]]$Z.hat.orig)), \n",
    "                                                                    # this exponential will cancel out the internal log transformation. \n",
    "                                                                    # so bMIND's raw output Z.hat will be fitted against log transformed X and true Z\n",
    "                                                                    eval.feature.source = sim.data.list[[t]]$eval.feature.source)\n",
    "    \n",
    "                                                                   #celltype by features\n",
    "    bMIND.mdl.list[[t]]$joint.bulk.Z.hat.log10p.diff = t(-log10(bMIND.mdl.list[[t]]$joint.bulk.p[,,\"Z.hat\"])) - t(-log10(bMIND.mdl.list[[t]]$joint.bulk.p[,,\"bulk\"]))\n",
    "    bMIND.mdl.list[[t]]$joint.bulk.Z.hat.log10p      = t(-log10(bMIND.mdl.list[[t]]$joint.bulk.p[,,\"Z.hat\"])) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>-0.230709697668944</li><li>-3.85011715806492</li><li>-1.23631103030767</li><li>-1.59653919911399</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item -0.230709697668944\n",
       "\\item -3.85011715806492\n",
       "\\item -1.23631103030767\n",
       "\\item -1.59653919911399\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. -0.230709697668944\n",
       "2. -3.85011715806492\n",
       "3. -1.23631103030767\n",
       "4. -1.59653919911399\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] -0.2307097 -3.8501172 -1.2363110 -1.5965392"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#with rough prior \n",
    "colMedians(bMIND.mdl.list[[1]]$joint.bulk.Z.hat.log10p.diff, na.rm = T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveRDS(bMIND.mdl.list,       file.path(res.dir, paste0(\"bMIND.mdl.rough.prior.list.rds\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bMIND sc prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (n == 500 & source.col == \"decon.L1\"){\n",
    "    bMIND.mdl.list = readRDS(file.path(res.dir, paste0(\"bMIND.mdl.sc.prior_all.list.rds\")))\n",
    "    for (t in ts){\n",
    "        sim.data.list[[t]]$eval.feature.source = calc_variable_feature_source(sim.data.list[[t]]$Z.scale, \n",
    "                                                                              variable_thr = 0.1, max_sds = max_stds)\n",
    "        bMIND.mdl.list[[t]]$joint.bulk.p = calc_joint_bulk_p_vals_array(X = sim.data.list[[t]]$X,\n",
    "                                                                        W = sim.data.list[[t]]$W,\n",
    "                                                                        Z = sim.data.list[[t]]$Z,\n",
    "\n",
    "                                                                        Z.hat = exp(none_neg_Z(bMIND.mdl.list[[t]]$Z.hat.orig)), \n",
    "                                                                        # this exponential will cancel out the internal log transformation. \n",
    "                                                                        # so bMIND's raw output Z.hat will be fitted against log transformed X and true Z\n",
    "                                                                        eval.feature.source = sim.data.list[[t]]$eval.feature.source)\n",
    "\n",
    "                                                                       #celltype by features\n",
    "        bMIND.mdl.list[[t]]$joint.bulk.Z.hat.log10p.diff = t(-log10(bMIND.mdl.list[[t]]$joint.bulk.p[,,\"Z.hat\"])) - t(-log10(bMIND.mdl.list[[t]]$joint.bulk.p[,,\"bulk\"]))\n",
    "        bMIND.mdl.list[[t]]$joint.bulk.Z.hat.log10p      = t(-log10(bMIND.mdl.list[[t]]$joint.bulk.p[,,\"Z.hat\"])) \n",
    "    }\n",
    "    print(colMedians(bMIND.mdl.list[[1]]$joint.bulk.Z.hat.log10p.diff, na.rm = T))\n",
    "    saveRDS(bMIND.mdl.list,       file.path(res.dir, paste0(\"bMIND.mdl.sc.prior_all.list.rds\")))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Seurat-V4",
   "language": "R",
   "name": "ir41"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
