{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“package ‘MASS’ was built under R version 4.1.3”\n",
      "Welcome to compositions, a package for compositional data analysis.\n",
      "Find an intro with \"? compositions\"\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: ‘compositions’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    anova, cor, cov, dist, var\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    %*%, norm, scale, scale.default\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(matrixStats)\n",
    "\n",
    "source(\"analysis.utils.r\")\n",
    "source(\"simulate.expression.utils.r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source.col = \"decon.L1\" \n",
    "# n = 500\n",
    "\n",
    "# source.col = \"decon.L2\" \n",
    "# n = 500\n",
    "\n",
    "# source.col = \"decon.L1\" \n",
    "# n = 250\n",
    "\n",
    "source.col = \"decon.L1\" \n",
    "n = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_stds = 2\n",
    "project.dir = \"/u/home/j/johnsonc/project-halperin/TCAx/TCAx2023/\"\n",
    "\n",
    "#relative path of the data dir to project.dir\n",
    "if(source.col == \"decon.L1\"){\n",
    "    data.dir   = paste0(\"Data/RNA/Simulation-PBMC/sc-Stephenson_all.W_decon.L1_HEF.10k_k_5_m_600_n_\", n, \"_dirichlet_F_noiseZ_T_varThr_1e-04_filThr_1e-04_expQtl_0_enrich_F_etpRat_0_enrichRat_0_maxSds_\", max_stds, \"_scale.maxSds_Inf_scale.factor.thr_1e-04/\")\n",
    "    res.dir    = paste0(\"Result/RNA/Simulation-PBMC/sc-Stephenson_all.W_decon.L1_HEF.10k_k_5_m_600_n_\", n, \"_dirichlet_F_noiseZ_T_varThr_1e-04_filThr_1e-04_expQtl_0_enrich_F_etpRat_0_enrichRat_0_maxSds_\", max_stds, \"_scale.maxSds_Inf_scale.factor.thr_1e-04/\")\n",
    "}else{\n",
    "    data.dir   = paste0(\"Data/RNA/Simulation-PBMC/sc-Stephenson_all.W_decon.L2_HEF.10k_k_7_m_600_n_\", n, \"_dirichlet_F_noiseZ_T_varThr_1e-04_filThr_1e-04_expQtl_0_enrich_F_etpRat_0_enrichRat_0_maxSds_\", max_stds, \"_scale.maxSds_Inf_scale.factor.thr_1e-04/\")\n",
    "    res.dir    = paste0(\"Result/RNA/Simulation-PBMC/sc-Stephenson_all.W_decon.L2_HEF.10k_k_7_m_600_n_\", n, \"_dirichlet_F_noiseZ_T_varThr_1e-04_filThr_1e-04_expQtl_0_enrich_F_etpRat_0_enrichRat_0_maxSds_\", max_stds, \"_scale.maxSds_Inf_scale.factor.thr_1e-04/\")\n",
    "}\n",
    "\n",
    "ts = 1:20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dir   = file.path(project.dir, data.dir)\n",
    "res.dir   = file.path(project.dir, res.dir)\n",
    "\n",
    "if (!file.exists(res.dir)){print(\"no result in the result directory\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"mp_0_vp_0.01_cp_0.01_maxStds_2\"\n"
     ]
    }
   ],
   "source": [
    "sim.data.list = readRDS(file.path(data.dir, \"sim.data.list.rds\"))\n",
    "\n",
    "# load TCA, baseline\n",
    "tca.mdl.list  = readRDS(file.path(res.dir, paste0(\"tca.mdl.list.rds\")))\n",
    "base.mdl.list = readRDS(file.path(res.dir, paste0(\"base.mdl.list.rds\")))\n",
    "cibersortx.mdl.list = readRDS(file.path(res.dir, paste0(\"cibersortx.mdl.list.rds\")))\n",
    "\n",
    "## load TCAx\n",
    "mean_penalty  = 0\n",
    "var_penalty   = 0.01\n",
    "covar_penalty = 0.01\n",
    "\n",
    "pen.config = paste(\"mp\", mean_penalty, \"vp\", var_penalty, \"cp\", covar_penalty, \"maxStds\", max_stds, sep =  \"_\")\n",
    "print(pen.config)\n",
    "\n",
    "tcax.mdl.list = readRDS(file.path(res.dir, paste0(\"tcax.mdl.\", pen.config, \".list.rds\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X: matrix of features by sample, bulk expression or methylation \n",
    "#W: matric of samples by sources, proportions\n",
    "#Z: array of sources by features by samples, ground truth Z\n",
    "#Z.hat: array of sources by features by samples, estiamted Z\n",
    "#eval.feature.source: matrix of logical features by sources, \n",
    "#if True, evaluate this feature-source, if False, skip it. all components will have pval1\n",
    "#num.stds: numeric, number of standard deviations away to be considered as outliers and removed from regression \n",
    "#constant_thr: numeric, miminal amount of variation in Z.hat to be considered worth fitting the regression \n",
    "#if fall below this number, Z.hat automoatically get pval 1. regression only fit on the rest of the components\n",
    "\n",
    "#per feature-source fit the following regression\n",
    "#log(1 + Z[feature-source]) ~ 1 + W[drop one celltype] + log(1 + bulk[feature]) + log(1 + Z.hat[feature-source])\n",
    "#add the - (min Z.hat) to all Z.hat if there are any negative values in that feature,source\n",
    "#remove 2sd outliers based on bulk\n",
    "\n",
    "#return an array of pvalues that is source.ids by features by compents participates in the regression \n",
    "\n",
    "calc_joint_bulk_p_vals_array = function(X, W, Z, Z.hat, eval.feature.source, num.stds = 2, constant_thr = 10**(-4)){\n",
    "    # if there are negative value, shift entire distribution \n",
    "    Z.hat = none_neg_Z(Z.hat)\n",
    "\n",
    "    m = nrow(X)\n",
    "    k = ncol(W)\n",
    "    feature.ids = rownames(X)\n",
    "    source.ids  = colnames(W)\n",
    "\n",
    "    # init to all 1 pval\n",
    "    p.vals.array = array(1, c(k, m, (1 + 1 + 1 + (k-1)))) # intercept, bulk, Z[,jl], W related,\n",
    "    dimnames(p.vals.array)[[1]] = source.ids \n",
    "    dimnames(p.vals.array)[[2]] = feature.ids\n",
    "    dimnames(p.vals.array)[[3]] = c(\"(Intercept)\", \"bulk\", \"Z.hat\", colnames(W)[-1])\n",
    "\n",
    "    for (source.id in source.ids){\n",
    "        for (feature.id in feature.ids){\n",
    "            if (!eval.feature.source[feature.id, source.id]){\n",
    "                p.vals.array[source.id, feature.id, ] = NA\n",
    "                next # skip this feature source due to no meaningful variable in the ground truth Z\n",
    "                # everything is set to NA\n",
    "            }else{\n",
    "                df = data.frame(Z     = log(1 + Z[source.id,feature.id,]),     \n",
    "                                bulk  = log(1 + X[feature.id, ]), \n",
    "                                Z.hat = log(1 + Z.hat[source.id,feature.id,]))\n",
    "                df = cbind(df, data.frame(W[,-1])) # drop one celltype\n",
    "                \n",
    "                \n",
    "                #filter out 2SD\n",
    "                x =  df$bulk\n",
    "                mask = abs(x - mean(x)) <= num.stds * sd(x)\n",
    "                df = df[mask, ]\n",
    "\n",
    "                if(sd(df$Z.hat) <= constant_thr){\n",
    "                    #if no variance detected in celltype h, gene j, \n",
    "                    df = df[, colnames(df)!= \"Z.hat\"]\n",
    "                    fit = lm(formula = Z ~ 1 + ., data = df) \n",
    "                    coef = summary(fit)$coefficients\n",
    "                    #prevent lm replacing the special characters in the colnames so hard code this\n",
    "                    p.vals.array[source.id, feature.id, c(\"(Intercept)\", \"bulk\", colnames(W[,-1]))] = t(coef[, \"Pr(>|t|)\", drop = F])\n",
    "                }else{\n",
    "                    fit = lm(formula = Z ~ 1 + ., data = df) \n",
    "                    coef = summary(fit)$coefficients\n",
    "                    p.vals.array[source.id, feature.id, ] = t(coef[, \"Pr(>|t|)\", drop = F])\n",
    "                }\n",
    "             }\n",
    "        }#end of feature\n",
    "    }#end of source\n",
    "    return(p.vals.array)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# running regression on all iterations, all methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "7.7 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "28.3 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "13.03 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "31.97 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "9.27 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "30.47 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "9.4 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "27.13 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "15.4 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "33.13 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "19.43 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "38.6 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "10.23 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "31.53 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "7.87 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "24.7 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "14.2 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "24.23 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "11.4 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "29.3 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "11.77 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "30 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "12 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "32.73 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "9.1 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "40.07 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "12.07 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "31.73 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "11.27 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "30.93 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "20.57 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "34.63 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "9.43 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "22.83 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "9.1 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "25.67 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "23.3 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "37.13 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "0 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "8.93 percent of the feature-source are shifted to be non negative\n",
      "\n",
      "24.03 percent of the feature-source are shifted to be non negative\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for (t in ts){\n",
    "    sim.data.list[[t]]$eval.feature.source = calc_variable_feature_source(sim.data.list[[t]]$Z.scale, \n",
    "                                                                          variable_thr = 0.1, max_sds = max_stds)\n",
    "\n",
    "    base.mdl.list[[t]]$joint.bulk.p = calc_joint_bulk_p_vals_array(X = sim.data.list[[t]]$X,\n",
    "                                                                   W = sim.data.list[[t]]$W,\n",
    "                                                                   Z = sim.data.list[[t]]$Z,\n",
    "                                                                   Z.hat = base.mdl.list[[t]]$Z.hat.orig,\n",
    "                                                                   eval.feature.source = sim.data.list[[t]]$eval.feature.source)\n",
    "\n",
    "    \n",
    "    cibersortx.mdl.list[[t]]$joint.bulk.p = calc_joint_bulk_p_vals_array(X = sim.data.list[[t]]$X,\n",
    "                                                                         W = sim.data.list[[t]]$W,\n",
    "                                                                         Z = sim.data.list[[t]]$Z,\n",
    "                                                                         Z.hat = cibersortx.mdl.list[[t]]$Z.hat.orig,\n",
    "                                                                         eval.feature.source = sim.data.list[[t]]$eval.feature.source)\n",
    "\n",
    "    tca.mdl.list[[t]]$joint.bulk.p = calc_joint_bulk_p_vals_array(X = sim.data.list[[t]]$X,\n",
    "                                                                  W = sim.data.list[[t]]$W,\n",
    "                                                                  Z = sim.data.list[[t]]$Z,\n",
    "                                                                  Z.hat = tca.mdl.list[[t]]$Z.hat.orig,\n",
    "                                                                  eval.feature.source = sim.data.list[[t]]$eval.feature.source)\n",
    "    \n",
    "    tcax.mdl.list[[t]]$joint.bulk.p = calc_joint_bulk_p_vals_array(X = sim.data.list[[t]]$X,\n",
    "                                                                   W = sim.data.list[[t]]$W,\n",
    "                                                                   Z = sim.data.list[[t]]$Z,\n",
    "                                                                   Z.hat = tcax.mdl.list[[t]]$Z.hat.orig,\n",
    "                                                                   eval.feature.source = sim.data.list[[t]]$eval.feature.source)\n",
    "     \n",
    "    \n",
    "    \n",
    "    #celltype by features\n",
    "    base.mdl.list[[t]]$joint.bulk.Z.hat.log10p.diff = t(-log10(base.mdl.list[[t]]$joint.bulk.p[,,\"Z.hat\"])) - t(-log10(base.mdl.list[[t]]$joint.bulk.p[,,\"bulk\"]))\n",
    "    base.mdl.list[[t]]$joint.bulk.Z.hat.log10p      = t(-log10(base.mdl.list[[t]]$joint.bulk.p[,,\"Z.hat\"])) \n",
    "    \n",
    "    cibersortx.mdl.list[[t]]$joint.bulk.Z.hat.log10p.diff = t(-log10(cibersortx.mdl.list[[t]]$joint.bulk.p[,,\"Z.hat\"])) - t(-log10(cibersortx.mdl.list[[t]]$joint.bulk.p[,,\"bulk\"]))\n",
    "    cibersortx.mdl.list[[t]]$joint.bulk.Z.hat.log10p      = t(-log10(cibersortx.mdl.list[[t]]$joint.bulk.p[,,\"Z.hat\"])) \n",
    "   \n",
    "    tca.mdl.list[[t]]$joint.bulk.Z.hat.log10p.diff = t(-log10(tca.mdl.list[[t]]$joint.bulk.p[,,\"Z.hat\"])) - t(-log10(tca.mdl.list[[t]]$joint.bulk.p[,,\"bulk\"]))\n",
    "    tca.mdl.list[[t]]$joint.bulk.Z.hat.log10p      = t(-log10(tca.mdl.list[[t]]$joint.bulk.p[,,\"Z.hat\"]))\n",
    "    \n",
    "    tcax.mdl.list[[t]]$joint.bulk.Z.hat.log10p.diff = t(-log10(tcax.mdl.list[[t]]$joint.bulk.p[,,\"Z.hat\"])) - t(-log10(tcax.mdl.list[[t]]$joint.bulk.p[,,\"bulk\"])) \n",
    "    tcax.mdl.list[[t]]$joint.bulk.Z.hat.log10p      = t(-log10(tcax.mdl.list[[t]]$joint.bulk.p[,,\"Z.hat\"]))\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>-5.15126610014892</li><li>-4.24374661143516</li><li>-2.64886054282476</li><li>-3.06730209895482</li><li>-2.55809614242327</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item -5.15126610014892\n",
       "\\item -4.24374661143516\n",
       "\\item -2.64886054282476\n",
       "\\item -3.06730209895482\n",
       "\\item -2.55809614242327\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. -5.15126610014892\n",
       "2. -4.24374661143516\n",
       "3. -2.64886054282476\n",
       "4. -3.06730209895482\n",
       "5. -2.55809614242327\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] -5.151266 -4.243747 -2.648861 -3.067302 -2.558096"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# just on the first round\n",
    "colMedians(base.mdl.list[[1]]$joint.bulk.Z.hat.log10p.diff, na.rm = T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>-2.29050256287711</li><li>-9.94490490323491</li><li>-7.46595585895233</li><li>-1.67704552384112</li><li>-3.43902608204739</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item -2.29050256287711\n",
       "\\item -9.94490490323491\n",
       "\\item -7.46595585895233\n",
       "\\item -1.67704552384112\n",
       "\\item -3.43902608204739\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. -2.29050256287711\n",
       "2. -9.94490490323491\n",
       "3. -7.46595585895233\n",
       "4. -1.67704552384112\n",
       "5. -3.43902608204739\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] -2.290503 -9.944905 -7.465956 -1.677046 -3.439026"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colMedians(cibersortx.mdl.list[[1]]$joint.bulk.Z.hat.log10p.diff, na.rm = T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>-3.94174359321882</li><li>-5.03346789697799</li><li>-1.57902505187947</li><li>-2.88474912954764</li><li>-2.20785984266689</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item -3.94174359321882\n",
       "\\item -5.03346789697799\n",
       "\\item -1.57902505187947\n",
       "\\item -2.88474912954764\n",
       "\\item -2.20785984266689\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. -3.94174359321882\n",
       "2. -5.03346789697799\n",
       "3. -1.57902505187947\n",
       "4. -2.88474912954764\n",
       "5. -2.20785984266689\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] -3.941744 -5.033468 -1.579025 -2.884749 -2.207860"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colMedians(tca.mdl.list[[1]]$joint.bulk.Z.hat.log10p.diff, na.rm = T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>0.276513739925418</li><li>-0.614907029599284</li><li>0.517253210070527</li><li>-0.352999136080658</li><li>-0.039710282434643</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0.276513739925418\n",
       "\\item -0.614907029599284\n",
       "\\item 0.517253210070527\n",
       "\\item -0.352999136080658\n",
       "\\item -0.039710282434643\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0.276513739925418\n",
       "2. -0.614907029599284\n",
       "3. 0.517253210070527\n",
       "4. -0.352999136080658\n",
       "5. -0.039710282434643\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]  0.27651374 -0.61490703  0.51725321 -0.35299914 -0.03971028"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "colMedians(tcax.mdl.list[[1]]$joint.bulk.Z.hat.log10p.diff, na.rm = T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveRDS(base.mdl.list,       file.path(res.dir, paste0(\"base.mdl.list.rds\"))) \n",
    "saveRDS(cibersortx.mdl.list, file.path(res.dir, paste0(\"cibersortx.mdl.list.rds\")))\n",
    "saveRDS(tca.mdl.list,        file.path(res.dir, paste0(\"tca.mdl.list.rds\")))\n",
    "saveRDS(tcax.mdl.list,       file.path(res.dir, paste0(\"tcax.mdl.\", pen.config, \".list.rds\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Seurat-V4",
   "language": "R",
   "name": "ir41"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
